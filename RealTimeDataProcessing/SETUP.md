# Scalable Real-Time Analytics System for Website Traffic

This project demonstrates a **scalable real-time analytics system** built using **Apache Kafka**, **Apache Spark**, and
**Cassandra** to analyze website clickstream data in real time.

## Table of Contents

1. [Prerequisites](#prerequisites)
2. [Setup Instructions](#setup-instructions)
    - [Start Docker Environment](#1-start-the-docker-environment)
    - [Run the Kafka Producer](#2-run-the-kafka-producer-fake-user-click-generator)
    - [Verify Kafka Messages](#3-verify-kafka-messages)
    - [Run the Spark Streaming Job](#4-run-the-spark-streaming-job)
    - [Set Up Cassandra Schema](#5-set-up-cassandra-schema)
    - [Verify Data in Cassandra](#6-verify-the-data-in-cassandra)
3. [System Architecture](#system-architecture)
4. [Install Cassandra Tools](#install-cassandra-tools)

---

## Prerequisites

Ensure you have the following software installed:

- [Docker](https://www.docker.com/)
- [Python 3.x](https://www.python.org/)
- Cassandra command-line tools (CQLSH)

---

## Setup Instructions

### 1. Start the Docker Environment

To bring up Kafka, Spark, Cassandra, and other necessary services in Docker, run:

```bash
docker compose up -d
```

This command will start all services in the background.

### 2. Run the Kafka Producer (Fake User Click Generator)

Simulate user click events by running the Kafka producer:

```bash
python clickstream_producer.py
```

This script generates fake clickstream events and sends them to Kafka.

### 3. Verify Kafka Messages

To verify that Kafka is receiving the messages, you can run the following Kafka consumer command to print messages from
the website_clicks topic:

```bash
kafka-console-consumer --bootstrap-server localhost:9093 --topic website_clicks --from-beginning
```

You should see clickstream events printed in the terminal.

### 4. Run the Spark Streaming Job

Process the Kafka clickstream data using Spark Streaming by running:

```bash
python spark_streaming.py
```

This Spark job will read events from Kafka, process them, and send the processed data to Cassandra.

### 5. Set Up Cassandra Schema

To set up the keyspace and table in Cassandra, run the following command to execute the cassandra_setup.cql script:

```bash
cqlsh localhost 9042 -f ./scripts/cassandra_setup.cql
```

Make sure the script is in the correct location and accessible.

### 6. Verify the Data in Cassandra

After the pipeline is running, you can query Cassandra to verify that the processed clickstream data is being stored:

```SQL
SELECT * FROM clickstream_ks.clicks;
```

This query will display the clickstream events stored in the clickstream_ks.clicks table.

## System Architecture

- Kafka: Streams real-time clickstream events generated by the producer (simulated user actions).
- Spark Streaming: Processes and enriches the events from Kafka, transforming them as necessary.
- Cassandra: Stores the processed clickstream data for efficient querying and analysis.

## Install Cassandra Tools

To run CQL (Cassandra Query Language) commands or execute scripts from your local machine, you need the Cassandra
command-line tools, especially cqlsh.

Install Cassandra Tools on macOS (Using Homebrew)

You can install Cassandra and its tools using Homebrew:

```bash
brew install cassandra
```

Install Cassandra Tools on Linux (Debian-based)

For Debian-based systems (like Ubuntu), you can install Cassandra tools using APT:

```bash
sudo apt-get update
sudo apt-get install cassandra
```

Install Cassandra Tools on Windows

For Windows, follow the official Cassandra installation guide to install Cassandra and cqlsh.

Once installed, you can use cqlsh to interact with Cassandra from your terminal.

```bash
cqlsh localhost 9042
```

This command will connect you to the Cassandra instance running on port 9042.

Enjoy experimenting with this scalable, real-time data pipeline!
